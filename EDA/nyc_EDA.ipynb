{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9FQSaq-6tfJ"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set()\n",
        "rand_state=1000"
      ],
      "metadata": {
        "id": "qTwhSd3b64kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('nyc-rolling-sales.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "ab3izrpP67Cz",
        "outputId": "d0c6fcbb-359d-4a67-e8dc-ff664cd1d179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'nyc-rolling-sales.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-57886bf1202e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nyc-rolling-sales.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nyc-rolling-sales.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "D16IN48d69Mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "id": "dBRL-n_T7y1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unnamed won't tell us anything in our analysis, it looks like just an index column."
      ],
      "metadata": {
        "id": "Mg-KEC7qQKkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop('Unnamed: 0', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "2C0jBjiC77lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constructing our variable types: SALE DATE as date, then our numerics and categoricals."
      ],
      "metadata": {
        "id": "Y7hr1TLgQVI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['SALE DATE'] = pd.to_datetime(df['SALE DATE'], errors='coerce')"
      ],
      "metadata": {
        "id": "rzLYCYmd9GgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numerics = [\"RESIDENTIAL UNITS\", \"COMMERCIAL UNITS\", \"TOTAL UNITS\", \"LAND SQUARE FEET\", \"GROSS SQUARE FEET\", \"SALE PRICE\"]\n",
        "categoricals = [\"BOROUGH\", \"NEIGHBORHOOD\", \"BUILDING CLASS CATEGORY\", \"TAX CLASS AT PRESENT\", \"BUILDING CLASS AT PRESENT\",\n",
        "                \"ZIP CODE\", \"YEAR BUILT\", \"TAX CLASS AT TIME OF SALE\", \"BUILDING CLASS AT TIME OF SALE\"]\n",
        "\n",
        "df[numerics]= df[numerics].apply(lambda x: pd.to_numeric(x, errors=\"coerce\"))\n",
        "df[categoricals]= df[categoricals].apply(lambda x: x.astype(\"category\"))"
      ],
      "metadata": {
        "id": "nrNHcsnh-Qbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Being able to look at the sale year and month could also be useful in our analysis, so we'll break out those columns as well."
      ],
      "metadata": {
        "id": "2zd-RU_2Qhui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['sale_year'] = pd.DatetimeIndex(df['SALE DATE']).year.astype(\"category\")\n",
        "df['sale_month'] = pd.DatetimeIndex(df['SALE DATE']).month.astype(\"category\")\n",
        "pd.crosstab(df['sale_month'],df['sale_year'])"
      ],
      "metadata": {
        "id": "8M6NG9yxAn5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "MyFJdFohAGNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's look for missing values:"
      ],
      "metadata": {
        "id": "SzMMUkEMQ_cA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "jUCxvCZuQ34j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.replace(to_replace=' ', value=np.nan, inplace=True)\n",
        "df.isna().sum() / len(df) * 100"
      ],
      "metadata": {
        "id": "StX4USTSy0nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='Greens')"
      ],
      "metadata": {
        "id": "k4L_V3WizSH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Easement is entirely blank, apartment number is around 77% blank, so let's drop those columns."
      ],
      "metadata": {
        "id": "WdeqQVsvRRph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['EASE-MENT', 'APARTMENT NUMBER'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "pLCaqRQ3zdWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.dropna()"
      ],
      "metadata": {
        "id": "RDyp-d7MxRwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum(df.duplicated())"
      ],
      "metadata": {
        "id": "oh2phsUaRhNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quite a few duplicates, we'll drop those, too.\n",
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "id": "HgdFbaciRj6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's look closer at our other missing data:"
      ],
      "metadata": {
        "id": "COpaChS5RyHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change all variables to numberic and look at the statistics\n",
        "temp = df.copy()\n",
        "for cols in temp.columns:\n",
        "    temp[cols]=pd.to_numeric(temp[cols], errors='coerce')\n",
        "\n",
        "temp.info()"
      ],
      "metadata": {
        "id": "KKXhT4_w2RQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp.describe().T"
      ],
      "metadata": {
        "id": "TQEbUz_S2Une"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at sale price first, because the data seems very skewed and has $0 values, which doesn't make any sense in terms of our analysis."
      ],
      "metadata": {
        "id": "GoPMBqVxSLtp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[(df['SALE PRICE']<10000) | (df['SALE PRICE']>10000000)]['SALE PRICE'].count() /len(df)"
      ],
      "metadata": {
        "id": "_GZNZs-B21hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2= df[(df['SALE PRICE']>10000) & (df['SALE PRICE']<10000000)].copy()\n",
        "df2['SALE PRICE'].describe()"
      ],
      "metadata": {
        "id": "W0ZjtW5_3a9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.distplot(df2['SALE PRICE'], kde=True, bins=50, rug=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TH-q7pwN5jg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot looks better, but it's still quite skewed."
      ],
      "metadata": {
        "id": "hxRmoE1xTf85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2= df2[(df2['SALE PRICE']<4000000)]\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.distplot(df2['SALE PRICE'], kde=True, bins=50, rug=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-aE7tKxZ_9xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That looks much more normal. It's still right skewed, but that makes sense for real estate prices because of luxury homes.\n",
        "\n",
        "Now let's look at Year Built:"
      ],
      "metadata": {
        "id": "pI5yMkyFTqiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of 0's\n",
        "df2[df2['YEAR BUILT']==0]['YEAR BUILT'].count()"
      ],
      "metadata": {
        "id": "PmSqk8N_DWs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3=df2[df2['YEAR BUILT']!=0].copy()\n",
        "sns.distplot(df3['YEAR BUILT'], bins=50, rug=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2-wQlvJstTWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This plot looks good. After removing zeroes, there are no major outliers or nonsensical data.\n",
        "\n",
        "Now units:"
      ],
      "metadata": {
        "id": "1YoHx3Ihue2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3[df3['TOTAL UNITS']==0]['TOTAL UNITS'].count()"
      ],
      "metadata": {
        "id": "iFUjA8b-toaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4=df3[df3['TOTAL UNITS']!=0].copy()\n",
        "sns.distplot(df4['TOTAL UNITS'], bins=50, rug=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jakJ3lCTv221"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most total units are on the low end, but we have a few outliers."
      ],
      "metadata": {
        "id": "Fh8gRLuGwbTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df4.describe().T"
      ],
      "metadata": {
        "id": "_3FXbzVyv502"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Better! We filtered out those nonsensical values."
      ],
      "metadata": {
        "id": "Jls9oQrZyHxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df4.info()"
      ],
      "metadata": {
        "id": "uO95-PjixK2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We likely don't need the details of an address; we'll get more information from the neighborhood and borough\n",
        "df4.drop(['BLOCK','LOT','ADDRESS'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Ag5IJH7xyNNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the borough category more readable\n",
        "df4['BOROUGH']= df4['BOROUGH'].map({1:'Manhattan', 2:'Bronx', 3: 'Brooklyn', 4:'Queens',5:'Staten Island'})\n",
        "df4.head()"
      ],
      "metadata": {
        "id": "fdpc1Dojye6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on what I know about NYC real estate, I would guess that borough likely has an effect on sales price."
      ],
      "metadata": {
        "id": "I90SQ3Qayt6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bar =df4[['BOROUGH', 'SALE PRICE']].groupby(by='BOROUGH').mean().sort_values(by='SALE PRICE', ascending=True).reset_index()\n",
        "df_bar"
      ],
      "metadata": {
        "id": "ngqvTw89yoUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(y = 'BOROUGH', x = 'SALE PRICE', data = df_bar, palette=\"Dark2\" )\n",
        "plt.title('Average SALE PRICE on each BOROUGH')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aq2AbJnDzEc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That seems like a correct assumption, because the average sales price varies quite a bit between boroughs. Manhattan is clearly the most expensive, with Staten Island being the cheapest borough."
      ],
      "metadata": {
        "id": "tCzMTlbOzDwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.boxplot(y = 'BOROUGH', x = 'SALE PRICE', data = df4, palette=\"Set1\" )\n",
        "plt.title('Box plots for SALE PRICE on each BOROUGH')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e0-CITcYzdXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manhattan sales prices are normally distributed with a wide range, so although it's the most expensive borough, buyers may still be able to find cheaper options. The Bronx and Staten Island have a similar range, but the Bronx has more higher priced outliers. Brooklyn is also a more affordable borough but is right skewed, which tells us that there are still quite a few higher priced sales. Queens is similar to Brooklyn, but less skewed and with a lower range, so it would be more affordable."
      ],
      "metadata": {
        "id": "xqTUm7on12qT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's look at number of sales per month."
      ],
      "metadata": {
        "id": "MXu5ykzG23fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bar=df4[['sale_month', 'SALE PRICE']].groupby(by='sale_month').count().sort_values(by='sale_month', ascending=True).reset_index()\n",
        "df_bar.columns.values[1]='Sales_count'\n",
        "df_bar"
      ],
      "metadata": {
        "id": "bzND7c2dy_xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(y = 'sale_month', x = 'Sales_count', data = df_bar, palette=\"Set2\" )\n",
        "plt.title('count SALEs by each month')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Cj9bgh-j3HKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's not a clear pattern here. The most popular months to buy/sell are March, June, September, and December, which are spaced relatively evenly throughout the yeat. The least popular month is August, which is surprising to me because I thought families would try to move before school."
      ],
      "metadata": {
        "id": "CPPPbeOt415F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_bar2 =df4[['sale_month', 'SALE PRICE']].groupby(by='sale_month').mean().sort_values(by='SALE PRICE', ascending=True).reset_index()\n",
        "df_bar"
      ],
      "metadata": {
        "id": "dvTuY4W25Rzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(y = 'sale_month', x = 'SALE PRICE', data = df_bar2, palette=\"Dark2\" )\n",
        "plt.title('Average SALE PRICE on each MONTH')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i9Px9I_w3JaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I was curious about the relationship between price and sale month, so I built this graph out as well. It seems relatively even -- I don't see a huge pattern here. It is interesting, though, that the month with the lowest sales, August, also has the highest average sales price; that could be related."
      ],
      "metadata": {
        "id": "VgVulcGa52qx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mov3ZPGC-MpK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}